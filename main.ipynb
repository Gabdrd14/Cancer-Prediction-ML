{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing LIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.26.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.1.3)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.17.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.5.2)\n",
      "Requirement already satisfied: imblearn in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.21.12)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.66.2)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from imblearn) (0.12.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.9.2)\n",
      "Requirement already satisfied: namex in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\gabri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\gabri\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "!{sys.executable} -m pip install numpy pandas tensorflow scikit-learn imblearn\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import itertools\n",
    "import sklearn\n",
    "import cv2\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import imblearn\n",
    "sns.set_style(\"darkgrid\")\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as ts\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D ,MaxPooling2D , Flatten , Dense , Activation , Dropout , BatchNormalization\n",
    "from tensorflow.keras.models import Model , load_model , Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam , Adamax\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick analysis of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0000</th>\n",
       "      <th>pixel0001</th>\n",
       "      <th>pixel0002</th>\n",
       "      <th>pixel0003</th>\n",
       "      <th>pixel0004</th>\n",
       "      <th>pixel0005</th>\n",
       "      <th>pixel0006</th>\n",
       "      <th>pixel0007</th>\n",
       "      <th>pixel0008</th>\n",
       "      <th>pixel0009</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel2343</th>\n",
       "      <th>pixel2344</th>\n",
       "      <th>pixel2345</th>\n",
       "      <th>pixel2346</th>\n",
       "      <th>pixel2347</th>\n",
       "      <th>pixel2348</th>\n",
       "      <th>pixel2349</th>\n",
       "      <th>pixel2350</th>\n",
       "      <th>pixel2351</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192</td>\n",
       "      <td>153</td>\n",
       "      <td>193</td>\n",
       "      <td>195</td>\n",
       "      <td>155</td>\n",
       "      <td>192</td>\n",
       "      <td>197</td>\n",
       "      <td>154</td>\n",
       "      <td>185</td>\n",
       "      <td>202</td>\n",
       "      <td>...</td>\n",
       "      <td>173</td>\n",
       "      <td>124</td>\n",
       "      <td>138</td>\n",
       "      <td>183</td>\n",
       "      <td>147</td>\n",
       "      <td>166</td>\n",
       "      <td>185</td>\n",
       "      <td>154</td>\n",
       "      <td>177</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>68</td>\n",
       "      <td>48</td>\n",
       "      <td>75</td>\n",
       "      <td>123</td>\n",
       "      <td>93</td>\n",
       "      <td>126</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>39</td>\n",
       "      <td>55</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>28</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>192</td>\n",
       "      <td>138</td>\n",
       "      <td>153</td>\n",
       "      <td>200</td>\n",
       "      <td>145</td>\n",
       "      <td>163</td>\n",
       "      <td>201</td>\n",
       "      <td>142</td>\n",
       "      <td>160</td>\n",
       "      <td>206</td>\n",
       "      <td>...</td>\n",
       "      <td>167</td>\n",
       "      <td>129</td>\n",
       "      <td>143</td>\n",
       "      <td>159</td>\n",
       "      <td>124</td>\n",
       "      <td>142</td>\n",
       "      <td>136</td>\n",
       "      <td>104</td>\n",
       "      <td>117</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>95</td>\n",
       "      <td>59</td>\n",
       "      <td>72</td>\n",
       "      <td>143</td>\n",
       "      <td>103</td>\n",
       "      <td>119</td>\n",
       "      <td>171</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>158</td>\n",
       "      <td>113</td>\n",
       "      <td>139</td>\n",
       "      <td>194</td>\n",
       "      <td>144</td>\n",
       "      <td>174</td>\n",
       "      <td>215</td>\n",
       "      <td>162</td>\n",
       "      <td>191</td>\n",
       "      <td>225</td>\n",
       "      <td>...</td>\n",
       "      <td>209</td>\n",
       "      <td>166</td>\n",
       "      <td>185</td>\n",
       "      <td>172</td>\n",
       "      <td>135</td>\n",
       "      <td>149</td>\n",
       "      <td>109</td>\n",
       "      <td>78</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2353 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0000  pixel0001  pixel0002  pixel0003  pixel0004  pixel0005  \\\n",
       "0        192        153        193        195        155        192   \n",
       "1         25         14         30         68         48         75   \n",
       "2        192        138        153        200        145        163   \n",
       "3         38         19         30         95         59         72   \n",
       "4        158        113        139        194        144        174   \n",
       "\n",
       "   pixel0006  pixel0007  pixel0008  pixel0009  ...  pixel2343  pixel2344  \\\n",
       "0        197        154        185        202  ...        173        124   \n",
       "1        123         93        126        158  ...         60         39   \n",
       "2        201        142        160        206  ...        167        129   \n",
       "3        143        103        119        171  ...         44         26   \n",
       "4        215        162        191        225  ...        209        166   \n",
       "\n",
       "   pixel2345  pixel2346  pixel2347  pixel2348  pixel2349  pixel2350  \\\n",
       "0        138        183        147        166        185        154   \n",
       "1         55         25         14         28         25         14   \n",
       "2        143        159        124        142        136        104   \n",
       "3         36         25         12         17         25         12   \n",
       "4        185        172        135        149        109         78   \n",
       "\n",
       "   pixel2351  label  \n",
       "0        177      2  \n",
       "1         27      2  \n",
       "2        117      2  \n",
       "3         15      2  \n",
       "4         92      2  \n",
       "\n",
       "[5 rows x 2353 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= \"archive\\hmnist_28_28_RGB.csv\"\n",
    "\n",
    "data = pd.read_csv(data)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating the Target variable \n",
    "\n",
    "In machine learning, for an obvious reason, you need to separate the target variable before training the model on it. This ensures that the model learns patterns from the input features rather than memorizing the target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Label = data['label']\n",
    "\n",
    "Data = data.drop(columns =['label'] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping the data for an image of 28×28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Data : (10015, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from imblearn.over_sampling import RandomOverSampler  \n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "Data = np.array(Data).reshape(-1 ,28,28,3)\n",
    "\n",
    "print(\"Shape Data :\", Data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 0, 0, 6], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Label = np.array(Label)\n",
    "\n",
    "Label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting labels for the different types of skin diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {\n",
    "4   : {'nv' : 'melanocytic nevi'},\n",
    "6   : {\"mel\": 'melanoma'},\n",
    "2   : {\"bkl\": 'benign keratosis-like lesions'},\n",
    "1   : {\"bcc\": 'basal cell carcinoma'},\n",
    "5   : {\"vasc\":\"pyogenic granulomas and hemorrhage\"},\n",
    "0   : {\"akiec\" : \"Actinic keratoses ans intraepithelial carcinomae\"},\n",
    "3   : {\"df\"  : \"dermatofibroma\"}\n",
    "\n",
    "\n",
    "}\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of the Train/Test dataset variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "X_train , X_test , y_train , y_test = train_test_split(Data ,\n",
    "                                                        Label ,\n",
    "                                                        test_size= 0.3,\n",
    "                                                        random_state=23) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing the Class Imbalance in the Dataset\n",
    "\n",
    "For better results, it is recommended to have a balanced number of samples across different classes in the dataset. To address class imbalance, we can use under-sampling or over-sampling techniques.\n",
    "\n",
    "Under-sampling: Reduces the number of samples in the majority class to match the minority class.\n",
    "\n",
    "Over-sampling: Increases the number of samples in the minority class by duplicating or generating new samples (e.g., using SMOTE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote= SMOTE()\n",
    "\n",
    "# Flatten the 4D data \n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "\n",
    "# Apply SMOTE on the flattened data\n",
    "X_train_res_flat, y_train_res = smote.fit_resample(X_train_flat , y_train)\n",
    "\n",
    "# Reshape X_train_res_flat back to 4D\n",
    "X_train_res = X_train_res_flat.reshape(X_train_res_flat.shape[0], X_train.shape[1], X_train.shape[2], X_train.shape[3])\n",
    "\n",
    "# Check the new distribution of the training data\n",
    "print(f\"Original dataset shape: {Counter(y_train)}\")\n",
    "print(f\"Resampled dataset shape: {Counter(y_train_res)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape :(7010, 28, 28, 3) \n",
      " X_test shape: [[[[235 164 178]\n",
      "   [225 154 166]\n",
      "   [232 155 169]\n",
      "   ...\n",
      "   [213 119 149]\n",
      "   [194 108 140]\n",
      "   [194 110 143]]\n",
      "\n",
      "  [[235 170 181]\n",
      "   [223 154 165]\n",
      "   [233 158 171]\n",
      "   ...\n",
      "   [200 106 139]\n",
      "   [193 106 138]\n",
      "   [196 110 142]]\n",
      "\n",
      "  [[235 169 179]\n",
      "   [232 161 172]\n",
      "   [233 163 174]\n",
      "   ...\n",
      "   [189 101 136]\n",
      "   [205 116 149]\n",
      "   [196 108 144]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[237 185 186]\n",
      "   [237 184 183]\n",
      "   [235 177 175]\n",
      "   ...\n",
      "   [221 146 155]\n",
      "   [213 132 147]\n",
      "   [212 131 149]]\n",
      "\n",
      "  [[238 184 187]\n",
      "   [237 181 183]\n",
      "   [238 183 179]\n",
      "   ...\n",
      "   [217 136 148]\n",
      "   [214 134 146]\n",
      "   [215 135 151]]\n",
      "\n",
      "  [[235 172 176]\n",
      "   [232 167 170]\n",
      "   [227 164 159]\n",
      "   ...\n",
      "   [218 138 151]\n",
      "   [217 140 153]\n",
      "   [216 141 156]]]\n",
      "\n",
      "\n",
      " [[[154 125 152]\n",
      "   [159 129 157]\n",
      "   [160 132 161]\n",
      "   ...\n",
      "   [151 120 150]\n",
      "   [150 120 149]\n",
      "   [148 118 146]]\n",
      "\n",
      "  [[157 128 157]\n",
      "   [160 130 158]\n",
      "   [162 133 162]\n",
      "   ...\n",
      "   [154 124 155]\n",
      "   [153 124 154]\n",
      "   [150 121 151]]\n",
      "\n",
      "  [[158 128 153]\n",
      "   [162 133 159]\n",
      "   [162 133 159]\n",
      "   ...\n",
      "   [154 124 154]\n",
      "   [154 125 156]\n",
      "   [150 120 150]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[162 131 160]\n",
      "   [163 134 164]\n",
      "   [168 141 172]\n",
      "   ...\n",
      "   [155 124 152]\n",
      "   [153 122 151]\n",
      "   [153 123 152]]\n",
      "\n",
      "  [[163 130 160]\n",
      "   [164 135 164]\n",
      "   [165 138 167]\n",
      "   ...\n",
      "   [156 124 152]\n",
      "   [153 121 150]\n",
      "   [153 124 152]]\n",
      "\n",
      "  [[162 130 161]\n",
      "   [164 135 165]\n",
      "   [165 137 166]\n",
      "   ...\n",
      "   [155 121 149]\n",
      "   [153 121 149]\n",
      "   [153 123 153]]]\n",
      "\n",
      "\n",
      " [[[155 115 153]\n",
      "   [165 126 163]\n",
      "   [172 136 172]\n",
      "   ...\n",
      "   [166 125 161]\n",
      "   [164 122 161]\n",
      "   [159 116 156]]\n",
      "\n",
      "  [[162 122 160]\n",
      "   [167 129 166]\n",
      "   [173 139 176]\n",
      "   ...\n",
      "   [167 127 165]\n",
      "   [167 128 166]\n",
      "   [163 123 163]]\n",
      "\n",
      "  [[165 126 163]\n",
      "   [170 134 169]\n",
      "   [176 142 177]\n",
      "   ...\n",
      "   [169 129 166]\n",
      "   [168 129 167]\n",
      "   [166 128 167]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[164 123 157]\n",
      "   [169 131 163]\n",
      "   [169 134 165]\n",
      "   ...\n",
      "   [173 132 173]\n",
      "   [171 130 174]\n",
      "   [169 129 173]]\n",
      "\n",
      "  [[161 121 156]\n",
      "   [166 126 159]\n",
      "   [170 132 164]\n",
      "   ...\n",
      "   [171 128 168]\n",
      "   [169 127 169]\n",
      "   [167 126 167]]\n",
      "\n",
      "  [[158 117 153]\n",
      "   [160 117 149]\n",
      "   [165 122 156]\n",
      "   ...\n",
      "   [170 127 165]\n",
      "   [167 122 163]\n",
      "   [165 122 163]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[197 172 172]\n",
      "   [197 173 174]\n",
      "   [197 173 170]\n",
      "   ...\n",
      "   [201 188 191]\n",
      "   [201 188 193]\n",
      "   [202 187 192]]\n",
      "\n",
      "  [[196 172 173]\n",
      "   [197 177 180]\n",
      "   [197 174 172]\n",
      "   ...\n",
      "   [200 185 189]\n",
      "   [199 184 186]\n",
      "   [200 184 185]]\n",
      "\n",
      "  [[196 174 173]\n",
      "   [197 176 175]\n",
      "   [197 174 173]\n",
      "   ...\n",
      "   [200 183 184]\n",
      "   [198 182 183]\n",
      "   [197 180 177]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[198 181 183]\n",
      "   [198 180 183]\n",
      "   [199 180 184]\n",
      "   ...\n",
      "   [206 190 193]\n",
      "   [205 187 190]\n",
      "   [203 186 185]]\n",
      "\n",
      "  [[198 181 182]\n",
      "   [198 181 183]\n",
      "   [199 181 185]\n",
      "   ...\n",
      "   [206 192 197]\n",
      "   [205 188 192]\n",
      "   [203 186 189]]\n",
      "\n",
      "  [[198 182 185]\n",
      "   [199 182 186]\n",
      "   [198 181 183]\n",
      "   ...\n",
      "   [207 192 196]\n",
      "   [205 190 194]\n",
      "   [202 187 194]]]\n",
      "\n",
      "\n",
      " [[[211 162 181]\n",
      "   [212 158 180]\n",
      "   [208 153 175]\n",
      "   ...\n",
      "   [209 159 173]\n",
      "   [208 165 179]\n",
      "   [207 170 185]]\n",
      "\n",
      "  [[209 168 184]\n",
      "   [210 163 183]\n",
      "   [210 157 178]\n",
      "   ...\n",
      "   [209 161 174]\n",
      "   [208 166 179]\n",
      "   [207 171 186]]\n",
      "\n",
      "  [[209 170 187]\n",
      "   [210 166 185]\n",
      "   [213 159 182]\n",
      "   ...\n",
      "   [207 168 182]\n",
      "   [208 170 183]\n",
      "   [208 172 185]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[214 161 181]\n",
      "   [212 168 184]\n",
      "   [213 168 187]\n",
      "   ...\n",
      "   [215 177 195]\n",
      "   [215 181 197]\n",
      "   [213 181 197]]\n",
      "\n",
      "  [[211 168 186]\n",
      "   [213 169 186]\n",
      "   [213 167 185]\n",
      "   ...\n",
      "   [215 179 197]\n",
      "   [214 183 198]\n",
      "   [212 180 197]]\n",
      "\n",
      "  [[210 175 192]\n",
      "   [213 173 191]\n",
      "   [214 169 186]\n",
      "   ...\n",
      "   [215 176 195]\n",
      "   [214 181 197]\n",
      "   [212 177 194]]]\n",
      "\n",
      "\n",
      " [[[ 12   7  12]\n",
      "   [ 31  17  27]\n",
      "   [ 67  45  57]\n",
      "   ...\n",
      "   [ 71  51  65]\n",
      "   [ 25  14  23]\n",
      "   [  5   3   6]]\n",
      "\n",
      "  [[ 19  10  17]\n",
      "   [ 50  31  43]\n",
      "   [ 87  63  74]\n",
      "   ...\n",
      "   [ 92  70  87]\n",
      "   [ 50  34  47]\n",
      "   [ 11   6  11]]\n",
      "\n",
      "  [[ 32  18  28]\n",
      "   [ 72  50  62]\n",
      "   [100  76  85]\n",
      "   ...\n",
      "   [103  81  99]\n",
      "   [ 76  56  73]\n",
      "   [ 29  17  27]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 26  15  24]\n",
      "   [ 85  63  81]\n",
      "   [118  92 111]\n",
      "   ...\n",
      "   [114  91 106]\n",
      "   [ 93  71  89]\n",
      "   [ 48  31  44]]\n",
      "\n",
      "  [[  8   3   7]\n",
      "   [ 52  35  49]\n",
      "   [105  81 100]\n",
      "   ...\n",
      "   [105  83  99]\n",
      "   [ 69  49  65]\n",
      "   [ 27  16  25]]\n",
      "\n",
      "  [[  4   2   4]\n",
      "   [ 22  13  21]\n",
      "   [ 78  55  73]\n",
      "   ...\n",
      "   [ 88  66  82]\n",
      "   [ 43  28  41]\n",
      "   [ 17   9  16]]]]\n",
      "y_train shape :(7010,) \n",
      " y_test shape: [2 4 4 ... 4 6 4]\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train shape :{X_train.shape} \\n X_test shape: {X_test}')\n",
    "\n",
    "print(f'y_train shape :{y_train.shape} \\n y_test shape: {y_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the variables in categorical type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "\n",
    "y_test =  to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=( 1./255),\n",
    "                            rotation_range = 10,\n",
    "                            zoom_range = 0.1,\n",
    "                            width_shift_range = 0.1,\n",
    "                            height_shift_range = 0.1)\n",
    "\n",
    "testgen = ImageDataGenerator(rescale=( 1./255))\n",
    "                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the learning rate reduction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
    "                                                patience = 2,\n",
    "                                                verbose = 1,\n",
    "                                                factor =  0.5,\n",
    "                                                min_lr = 0.0001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, ReLU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# 🔹 Création du modèle\n",
    "model = Sequential()\n",
    "\n",
    "# Input\n",
    "model.add(Input(shape=(28, 28, 3)))\n",
    "\n",
    "# Block 1\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_initializer='he_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "# Block 2\n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_initializer='he_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "# Block 3\n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_initializer='he_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "# Flatten + Fully Connected Layers\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dropout(0.6))  \n",
    "model.add(Dense(256, activation='relu', kernel_regularizer=regularizers.L2(0.0005)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dense(7, activation='softmax', kernel_initializer='glorot_uniform'))\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0003, decay=1e-5), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=50,  # On augmente un peu les epochs pour plus de précision\n",
    "                    batch_size=128,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[lr_scheduler, early_stopping])\n",
    "\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8468 - loss: 0.5656\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7781 - loss: 0.7792\n",
      "Train Loss : 0.5543563365936279\n",
      "Train_accuracy :  0.8526390790939331\n",
      "Test Loss :  0.7589062452316284\n",
      "Test accuracy :  0.781364381313324\n"
     ]
    }
   ],
   "source": [
    "train_score = model.evaluate(X_train, y_train , verbose = 1)\n",
    "test_score = model.evaluate(X_test , y_test , verbose =  1)\n",
    "\n",
    "\n",
    "print(\"Train Loss :\", train_score[0])\n",
    "print(\"Train_accuracy : \",train_score[1])\n",
    "\n",
    "\n",
    "print(\"Test Loss : \" , test_score[0])\n",
    "print('Test accuracy : ', test_score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick conclusion\n",
    "\n",
    "As we can see, the model can detect whether a spot on your skin is malignant within an acceptable range. However, there is room for improvement in the model to reduce the significant loss during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_optimized.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7781 - loss: 0.7792\n",
      "Test Loss: 0.7589062452316284\n",
      "Test Accuracy: 0.781364381313324\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the optimized model\n",
    "model = load_model('model_optimized.keras')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_score = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "# Display the test loss and accuracy\n",
    "test_loss, test_accuracy = test_score\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
