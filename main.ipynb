{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing LIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "!{sys.executable} -m pip install numpy pandas tensorflow scikit-learn imblearn\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import itertools\n",
    "import sklearn\n",
    "import cv2\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import imblearn\n",
    "sns.set_style(\"darkgrid\")\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as ts\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D ,MaxPooling2D , Flatten , Dense , Activation , Dropout , BatchNormalization\n",
    "from tensorflow.keras.models import Model , load_model , Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam , Adamax\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick analysis of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0000</th>\n",
       "      <th>pixel0001</th>\n",
       "      <th>pixel0002</th>\n",
       "      <th>pixel0003</th>\n",
       "      <th>pixel0004</th>\n",
       "      <th>pixel0005</th>\n",
       "      <th>pixel0006</th>\n",
       "      <th>pixel0007</th>\n",
       "      <th>pixel0008</th>\n",
       "      <th>pixel0009</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel2343</th>\n",
       "      <th>pixel2344</th>\n",
       "      <th>pixel2345</th>\n",
       "      <th>pixel2346</th>\n",
       "      <th>pixel2347</th>\n",
       "      <th>pixel2348</th>\n",
       "      <th>pixel2349</th>\n",
       "      <th>pixel2350</th>\n",
       "      <th>pixel2351</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192</td>\n",
       "      <td>153</td>\n",
       "      <td>193</td>\n",
       "      <td>195</td>\n",
       "      <td>155</td>\n",
       "      <td>192</td>\n",
       "      <td>197</td>\n",
       "      <td>154</td>\n",
       "      <td>185</td>\n",
       "      <td>202</td>\n",
       "      <td>...</td>\n",
       "      <td>173</td>\n",
       "      <td>124</td>\n",
       "      <td>138</td>\n",
       "      <td>183</td>\n",
       "      <td>147</td>\n",
       "      <td>166</td>\n",
       "      <td>185</td>\n",
       "      <td>154</td>\n",
       "      <td>177</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>68</td>\n",
       "      <td>48</td>\n",
       "      <td>75</td>\n",
       "      <td>123</td>\n",
       "      <td>93</td>\n",
       "      <td>126</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>39</td>\n",
       "      <td>55</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>28</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>192</td>\n",
       "      <td>138</td>\n",
       "      <td>153</td>\n",
       "      <td>200</td>\n",
       "      <td>145</td>\n",
       "      <td>163</td>\n",
       "      <td>201</td>\n",
       "      <td>142</td>\n",
       "      <td>160</td>\n",
       "      <td>206</td>\n",
       "      <td>...</td>\n",
       "      <td>167</td>\n",
       "      <td>129</td>\n",
       "      <td>143</td>\n",
       "      <td>159</td>\n",
       "      <td>124</td>\n",
       "      <td>142</td>\n",
       "      <td>136</td>\n",
       "      <td>104</td>\n",
       "      <td>117</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>95</td>\n",
       "      <td>59</td>\n",
       "      <td>72</td>\n",
       "      <td>143</td>\n",
       "      <td>103</td>\n",
       "      <td>119</td>\n",
       "      <td>171</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>158</td>\n",
       "      <td>113</td>\n",
       "      <td>139</td>\n",
       "      <td>194</td>\n",
       "      <td>144</td>\n",
       "      <td>174</td>\n",
       "      <td>215</td>\n",
       "      <td>162</td>\n",
       "      <td>191</td>\n",
       "      <td>225</td>\n",
       "      <td>...</td>\n",
       "      <td>209</td>\n",
       "      <td>166</td>\n",
       "      <td>185</td>\n",
       "      <td>172</td>\n",
       "      <td>135</td>\n",
       "      <td>149</td>\n",
       "      <td>109</td>\n",
       "      <td>78</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2353 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0000  pixel0001  pixel0002  pixel0003  pixel0004  pixel0005  \\\n",
       "0        192        153        193        195        155        192   \n",
       "1         25         14         30         68         48         75   \n",
       "2        192        138        153        200        145        163   \n",
       "3         38         19         30         95         59         72   \n",
       "4        158        113        139        194        144        174   \n",
       "\n",
       "   pixel0006  pixel0007  pixel0008  pixel0009  ...  pixel2343  pixel2344  \\\n",
       "0        197        154        185        202  ...        173        124   \n",
       "1        123         93        126        158  ...         60         39   \n",
       "2        201        142        160        206  ...        167        129   \n",
       "3        143        103        119        171  ...         44         26   \n",
       "4        215        162        191        225  ...        209        166   \n",
       "\n",
       "   pixel2345  pixel2346  pixel2347  pixel2348  pixel2349  pixel2350  \\\n",
       "0        138        183        147        166        185        154   \n",
       "1         55         25         14         28         25         14   \n",
       "2        143        159        124        142        136        104   \n",
       "3         36         25         12         17         25         12   \n",
       "4        185        172        135        149        109         78   \n",
       "\n",
       "   pixel2351  label  \n",
       "0        177      2  \n",
       "1         27      2  \n",
       "2        117      2  \n",
       "3         15      2  \n",
       "4         92      2  \n",
       "\n",
       "[5 rows x 2353 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= \"archive\\hmnist_28_28_RGB.csv\"\n",
    "\n",
    "data = pd.read_csv(data)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating the Target variable \n",
    "\n",
    "In machine learning, for an obvious reason, you need to separate the target variable before training the model on it. This ensures that the model learns patterns from the input features rather than memorizing the target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "Label = data['label']\n",
    "\n",
    "Data = data.drop(columns =['label'] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping the data for an image of 28×28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Data : (10015, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from imblearn.over_sampling import RandomOverSampler  \n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "Data = np.array(Data).reshape(-1 ,28,28,3)\n",
    "\n",
    "print(\"Shape Data :\", Data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 0, 0, 6], dtype=int64)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Label = np.array(Label)\n",
    "\n",
    "Label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting labels for the different types of skin diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {\n",
    "4   : {'nv' : 'melanocytic nevi'},\n",
    "6   : {\"mel\": 'melanoma'},\n",
    "2   : {\"bkl\": 'benign keratosis-like lesions'},\n",
    "1   : {\"bcc\": 'basal cell carcinoma'},\n",
    "5   : {\"vasc\":\"pyogenic granulomas and hemorrhage\"},\n",
    "0   : {\"akiec\" : \"Actinic keratoses ans intraepithelial carcinomae\"},\n",
    "3   : {\"df\"  : \"dermatofibroma\"}\n",
    "\n",
    "\n",
    "}\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of the Train/Test dataset variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "X_train , X_test , y_train , y_test = train_test_split(Data ,\n",
    "                                                        Label ,\n",
    "                                                        test_size= 0.20,\n",
    "                                                        random_state=23) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing the Class Imbalance in the Dataset\n",
    "\n",
    "For better results, it is recommended to have a balanced number of samples across different classes in the dataset. To address class imbalance, we can use under-sampling or over-sampling techniques.\n",
    "\n",
    "Under-sampling: Reduces the number of samples in the majority class to match the minority class.\n",
    "\n",
    "Over-sampling: Increases the number of samples in the minority class by duplicating or generating new samples (e.g., using SMOTE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: Counter({4: 5348, 6: 901, 2: 867, 1: 414, 0: 269, 5: 118, 3: 95})\n",
      "Resampled dataset shape: Counter({4: 5348, 2: 5348, 6: 5348, 0: 5348, 5: 5348, 1: 5348, 3: 5348})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Flatten the 4D data \n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "\n",
    "# Apply SMOTE on the flattened data\n",
    "X_train_res_flat, y_train_res = smote.fit_resample(X_train_flat, y_train)\n",
    "\n",
    "# Reshape X_train_res_flat back to 4D\n",
    "X_train_res = X_train_res_flat.reshape(X_train_res_flat.shape[0], X_train.shape[1], X_train.shape[2], X_train.shape[3])\n",
    "\n",
    "# Check the new distribution of the training data\n",
    "print(f\"Original dataset shape: {Counter(y_train)}\")\n",
    "print(f\"Resampled dataset shape: {Counter(y_train_res)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape :(8012, 28, 28, 3) \n",
      " X_test shape: [[[[235 164 178]\n",
      "   [225 154 166]\n",
      "   [232 155 169]\n",
      "   ...\n",
      "   [213 119 149]\n",
      "   [194 108 140]\n",
      "   [194 110 143]]\n",
      "\n",
      "  [[235 170 181]\n",
      "   [223 154 165]\n",
      "   [233 158 171]\n",
      "   ...\n",
      "   [200 106 139]\n",
      "   [193 106 138]\n",
      "   [196 110 142]]\n",
      "\n",
      "  [[235 169 179]\n",
      "   [232 161 172]\n",
      "   [233 163 174]\n",
      "   ...\n",
      "   [189 101 136]\n",
      "   [205 116 149]\n",
      "   [196 108 144]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[237 185 186]\n",
      "   [237 184 183]\n",
      "   [235 177 175]\n",
      "   ...\n",
      "   [221 146 155]\n",
      "   [213 132 147]\n",
      "   [212 131 149]]\n",
      "\n",
      "  [[238 184 187]\n",
      "   [237 181 183]\n",
      "   [238 183 179]\n",
      "   ...\n",
      "   [217 136 148]\n",
      "   [214 134 146]\n",
      "   [215 135 151]]\n",
      "\n",
      "  [[235 172 176]\n",
      "   [232 167 170]\n",
      "   [227 164 159]\n",
      "   ...\n",
      "   [218 138 151]\n",
      "   [217 140 153]\n",
      "   [216 141 156]]]\n",
      "\n",
      "\n",
      " [[[154 125 152]\n",
      "   [159 129 157]\n",
      "   [160 132 161]\n",
      "   ...\n",
      "   [151 120 150]\n",
      "   [150 120 149]\n",
      "   [148 118 146]]\n",
      "\n",
      "  [[157 128 157]\n",
      "   [160 130 158]\n",
      "   [162 133 162]\n",
      "   ...\n",
      "   [154 124 155]\n",
      "   [153 124 154]\n",
      "   [150 121 151]]\n",
      "\n",
      "  [[158 128 153]\n",
      "   [162 133 159]\n",
      "   [162 133 159]\n",
      "   ...\n",
      "   [154 124 154]\n",
      "   [154 125 156]\n",
      "   [150 120 150]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[162 131 160]\n",
      "   [163 134 164]\n",
      "   [168 141 172]\n",
      "   ...\n",
      "   [155 124 152]\n",
      "   [153 122 151]\n",
      "   [153 123 152]]\n",
      "\n",
      "  [[163 130 160]\n",
      "   [164 135 164]\n",
      "   [165 138 167]\n",
      "   ...\n",
      "   [156 124 152]\n",
      "   [153 121 150]\n",
      "   [153 124 152]]\n",
      "\n",
      "  [[162 130 161]\n",
      "   [164 135 165]\n",
      "   [165 137 166]\n",
      "   ...\n",
      "   [155 121 149]\n",
      "   [153 121 149]\n",
      "   [153 123 153]]]\n",
      "\n",
      "\n",
      " [[[155 115 153]\n",
      "   [165 126 163]\n",
      "   [172 136 172]\n",
      "   ...\n",
      "   [166 125 161]\n",
      "   [164 122 161]\n",
      "   [159 116 156]]\n",
      "\n",
      "  [[162 122 160]\n",
      "   [167 129 166]\n",
      "   [173 139 176]\n",
      "   ...\n",
      "   [167 127 165]\n",
      "   [167 128 166]\n",
      "   [163 123 163]]\n",
      "\n",
      "  [[165 126 163]\n",
      "   [170 134 169]\n",
      "   [176 142 177]\n",
      "   ...\n",
      "   [169 129 166]\n",
      "   [168 129 167]\n",
      "   [166 128 167]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[164 123 157]\n",
      "   [169 131 163]\n",
      "   [169 134 165]\n",
      "   ...\n",
      "   [173 132 173]\n",
      "   [171 130 174]\n",
      "   [169 129 173]]\n",
      "\n",
      "  [[161 121 156]\n",
      "   [166 126 159]\n",
      "   [170 132 164]\n",
      "   ...\n",
      "   [171 128 168]\n",
      "   [169 127 169]\n",
      "   [167 126 167]]\n",
      "\n",
      "  [[158 117 153]\n",
      "   [160 117 149]\n",
      "   [165 122 156]\n",
      "   ...\n",
      "   [170 127 165]\n",
      "   [167 122 163]\n",
      "   [165 122 163]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[236 158 170]\n",
      "   [236 159 171]\n",
      "   [241 163 175]\n",
      "   ...\n",
      "   [236 155 173]\n",
      "   [231 150 170]\n",
      "   [231 155 171]]\n",
      "\n",
      "  [[237 159 169]\n",
      "   [237 161 172]\n",
      "   [238 160 172]\n",
      "   ...\n",
      "   [235 160 175]\n",
      "   [231 157 171]\n",
      "   [230 156 169]]\n",
      "\n",
      "  [[235 158 167]\n",
      "   [238 161 172]\n",
      "   [236 160 172]\n",
      "   ...\n",
      "   [235 161 172]\n",
      "   [232 160 172]\n",
      "   [230 157 169]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[229 167 167]\n",
      "   [233 171 173]\n",
      "   [236 173 177]\n",
      "   ...\n",
      "   [234 169 177]\n",
      "   [231 165 171]\n",
      "   [228 166 172]]\n",
      "\n",
      "  [[228 166 166]\n",
      "   [233 170 172]\n",
      "   [234 171 175]\n",
      "   ...\n",
      "   [236 171 178]\n",
      "   [230 167 173]\n",
      "   [226 164 169]]\n",
      "\n",
      "  [[226 165 166]\n",
      "   [230 168 170]\n",
      "   [234 171 175]\n",
      "   ...\n",
      "   [233 168 174]\n",
      "   [229 166 172]\n",
      "   [226 163 168]]]\n",
      "\n",
      "\n",
      " [[[237 141 161]\n",
      "   [238 151 175]\n",
      "   [238 158 179]\n",
      "   ...\n",
      "   [238 143 152]\n",
      "   [239 139 155]\n",
      "   [240 153 165]]\n",
      "\n",
      "  [[238 159 176]\n",
      "   [238 166 186]\n",
      "   [238 165 183]\n",
      "   ...\n",
      "   [242 125 144]\n",
      "   [240 121 137]\n",
      "   [240 143 155]]\n",
      "\n",
      "  [[237 144 163]\n",
      "   [237 150 174]\n",
      "   [237 162 183]\n",
      "   ...\n",
      "   [243 156 171]\n",
      "   [239 129 138]\n",
      "   [236 113 114]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[231 117 127]\n",
      "   [233 120 136]\n",
      "   [236 117 141]\n",
      "   ...\n",
      "   [239 141 155]\n",
      "   [239 133 146]\n",
      "   [237 132 132]]\n",
      "\n",
      "  [[234 138 152]\n",
      "   [236 132 152]\n",
      "   [235 116 142]\n",
      "   ...\n",
      "   [239 155 161]\n",
      "   [237 119 125]\n",
      "   [237 120 115]]\n",
      "\n",
      "  [[232 135 146]\n",
      "   [233 118 136]\n",
      "   [232 109 133]\n",
      "   ...\n",
      "   [239 175 179]\n",
      "   [237 152 148]\n",
      "   [237 134 126]]]\n",
      "\n",
      "\n",
      " [[[168 139 169]\n",
      "   [166 133 160]\n",
      "   [162 127 148]\n",
      "   ...\n",
      "   [170 140 177]\n",
      "   [172 143 180]\n",
      "   [171 143 178]]\n",
      "\n",
      "  [[167 137 162]\n",
      "   [167 137 168]\n",
      "   [164 131 157]\n",
      "   ...\n",
      "   [170 139 170]\n",
      "   [167 136 168]\n",
      "   [169 140 174]]\n",
      "\n",
      "  [[168 141 168]\n",
      "   [168 140 170]\n",
      "   [164 132 154]\n",
      "   ...\n",
      "   [169 137 165]\n",
      "   [169 140 171]\n",
      "   [166 135 162]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[147 113 136]\n",
      "   [145 113 138]\n",
      "   [143 112 137]\n",
      "   ...\n",
      "   [163 132 159]\n",
      "   [165 134 160]\n",
      "   [164 133 160]]\n",
      "\n",
      "  [[140 104 127]\n",
      "   [147 113 140]\n",
      "   [142 111 136]\n",
      "   ...\n",
      "   [163 132 161]\n",
      "   [162 129 151]\n",
      "   [162 128 151]]\n",
      "\n",
      "  [[141 107 131]\n",
      "   [142 109 134]\n",
      "   [144 111 135]\n",
      "   ...\n",
      "   [162 132 160]\n",
      "   [161 129 154]\n",
      "   [162 128 153]]]]\n",
      "y_train shape :(8012,) \n",
      " y_test shape: [2 4 4 ... 4 0 2]\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train shape :{X_train.shape} \\n X_test shape: {X_test}')\n",
    "\n",
    "print(f'y_train shape :{y_train.shape} \\n y_test shape: {y_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the variables in categorical type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "\n",
    "y_test =  to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=( 1./255),\n",
    "                            rotation_range = 10,\n",
    "                            zoom_range = 0.1,\n",
    "                            width_shift_range = 0.1,\n",
    "                            height_shift_range = 0.1)\n",
    "\n",
    "testgen = ImageDataGenerator(rescale=( 1./255))\n",
    "                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the learning rate reduction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
    "                                                patience = 2,\n",
    "                                                verbose = 1,\n",
    "                                                factor =  0.5,\n",
    "                                                min_lr = 0.0001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "\n",
    "\n",
    "model.add(keras.layers.Input(shape=[28 , 28, 3]))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation= 'relu', padding='same', kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.MaxPooling2D())\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, (3,3), activation= 'relu', padding='same', kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.Conv2D(64, (3,3), activation= 'relu', padding='same', kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.MaxPooling2D())\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(keras.layers.Conv2D(128, (3,3), activation= 'relu', padding='same', kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.Conv2D(128, (3,3), activation= 'relu', padding='same', kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.MaxPooling2D())\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(keras.layers.Conv2D(256, (3,3), activation= 'relu', padding='same', kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.Conv2D(256, (3,3), activation= 'relu', padding='same', kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.MaxPooling2D())\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "\n",
    "\n",
    "model.add(keras.layers.Dropout(rate=0.6))\n",
    "model.add(keras.layers.Dense(units= 256, activation='relu',  kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(units= 128, activation='relu',  kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(units= 64, activation='relu',  kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(units= 32, activation='relu',  kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(keras.layers.Dense(units=32 ,activation='relu', kernel_initializer='he_normal',kernel_regularizer = regularizers.L1L2()))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Dense(units = 7, activation = 'softmax' , kernel_initializer = 'glorot_uniform', name = 'classifier'))\n",
    "\n",
    "model.compile(Adamax(learning_rate=0.001), loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs =25,\n",
    "                    batch_size = 128,\n",
    "                    validation_data =(X_test , y_test),\n",
    "                    callbacks = [learning_rate_reduction])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = model.evaluate(X_train, y_train , verbose = 1)\n",
    "test_score = model.evaluate(X_test , y_test , verbose =  1)\n",
    "\n",
    "\n",
    "print(\"Train Loss :\", train_score[0])\n",
    "print(\"Train_accuracy : \",train_score[1])\n",
    "\n",
    "\n",
    "print(\"Test Loss : \" , test_score[0])\n",
    "print('Test accuracy : ', test_score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array(y_test)\n",
    "\n",
    "y_pred = np.array(X_test)\n",
    "\n",
    "y_pred = np.argmax(y_pred , axis = 1)\n",
    "y_true = np.argmax(y_true , axis = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
